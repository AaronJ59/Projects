{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pmq3RcFuacBf",
        "outputId": "188ee3d0-f13c-412f-8a51-08ec9c644ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'Projects'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
            "remote: Compressing objects: 100% (96/96), done.\u001b[K\n",
            "remote: Total 163 (delta 33), reused 10 (delta 1), pack-reused 54 (from 2)\u001b[K\n",
            "Receiving objects: 100% (163/163), 109.87 MiB | 36.80 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "mv: cannot stat 'Projects/BiteID/models': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "\n",
        "try:\n",
        "  from modular import download_image_data, data_setup, train_model, save\n",
        "except:\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/AaronJ59/Projects.git\n",
        "  !mv Projects/BiteID/modular/modular modular\n",
        "  !mv Projects/BiteID/models models\n",
        "  from modular import download_image_data, data_setup, train_model, save\n",
        "  !rm -rf Projects\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "bEEkOkROf11K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "apnsuNYMe-ZP",
        "outputId": "f4dcf644-62b8-4b2b-83d5-692901091eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"data/food80_binary\")\n",
        "\n",
        "with zipfile.ZipFile(\"food80_binary.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall(\"data/food80_binary\")"
      ],
      "metadata": {
        "id": "lavWfTntfDsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(seed:int=42):\n",
        "\n",
        "\n",
        "  # Import efficientnetb2\n",
        "\n",
        "  # Get the weights, transforms of the model and make the model\n",
        "  efficientnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  effnetb2_transform = efficientnetb2_weights.transforms()\n",
        "  effnetb2 = torchvision.models.efficientnet_b2(weights=efficientnetb2_weights)\n",
        "\n",
        "  # Freeze the base layers of efficientnetb2\n",
        "  for param in effnetb2.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "  # Change classifier head of effnetb2 to suit binary classification\n",
        "  torch.manual_seed(seed)\n",
        "  effnetb2.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3, inplace=True),\n",
        "      nn.Linear(in_features=1408, out_features=1), # 1 out_feature because I'm making a binary feature extractor\n",
        "  )\n",
        "\n",
        "  return effnetb2, effnetb2_transform\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create an instance\n",
        "effnetb2, effnetb2_transform = create_effnetb2_model(seed=42)"
      ],
      "metadata": {
        "id": "uvRak8jP2cYx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22ad93d-85a0-438b-b8f4-820a2be22e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 71.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = Path(\"data\")\n",
        "train_dir = data_dir / \"food80_binary\" / \"train\"\n",
        "test_dir = data_dir / \"food80_binary\" / \"test\"\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()"
      ],
      "metadata": {
        "id": "4idogzlNhPi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                                               test_dir=test_dir,\n",
        "                                                                               transform=effnetb2_transform,\n",
        "                                                                               num_workers=NUM_WORKERS,\n",
        "                                                                               batch_size=32)"
      ],
      "metadata": {
        "id": "PefyhmiyUkoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=effnetb2.parameters(),\n",
        "                             lr=.001)\n",
        "\n",
        "loss_fn = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "9tV-nUSYUpcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.dataloader,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               device: torch.device):\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.float().to(device)\n",
        "\n",
        "    # Do the forward pass\n",
        "    y_pred_logits = model(X).squeeze(dim=1)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = loss_fn(y_pred_logits, y)\n",
        "    train_loss = train_loss + loss.item()\n",
        "\n",
        "\n",
        "    # Optimize graidnet\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # prediction logits to hard 0 or 1 predictions by thresholding at 0.0\n",
        "    y_pred_labels = (y_pred_logits >= 0).long()\n",
        "    # Calculate the accuracy for the current batch by dividing the number of correct predictions\n",
        "    # by the batch size, and add it to the running total accuracy.\n",
        "    train_acc = train_acc + ((y_pred_labels == y.long()).sum().item() / len(y_pred_labels))\n",
        "\n",
        "  # Get average accuracy and loss per batch\n",
        "  train_loss = train_loss / len(dataloader)\n",
        "  train_acc = train_acc / len(dataloader)\n",
        "\n",
        "  return train_loss, train_acc\n",
        "\n"
      ],
      "metadata": {
        "id": "1L2GUecR79Lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      X, y = X.to(device), y.float().to(device)\n",
        "\n",
        "      # Do the forward pass\n",
        "      test_pred_logits = model(X).squeeze(dim=1)\n",
        "\n",
        "\n",
        "      # Calculate the loss\n",
        "      loss = loss_fn(test_pred_logits, y)\n",
        "      test_loss = test_loss + loss.item()\n",
        "\n",
        "      # prediction logits to prediction label\n",
        "      test_pred_labels = (test_pred_logits >= 0).long()\n",
        "\n",
        "      test_acc = test_acc + ((test_pred_labels == y.long()).sum().item() / len(test_pred_labels))\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "\n",
        "    return test_loss, test_acc\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4yEGS8W4V7xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          device: device,\n",
        "          epochs: int):\n",
        "\n",
        "  results = {\n",
        "      \"train_loss\": [],\n",
        "      \"train_acc\": [],\n",
        "      \"test_loss\": [],\n",
        "      \"test_acc\": []\n",
        "  }\n",
        "\n",
        "  model.to(device)\n",
        "  print(f\"Training model for {epochs} epochs\")\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       optimizer=optimizer,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       device=device)\n",
        "\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "\n",
        "\n",
        "    print(f\"\\nEpoch: {epoch} | train_loss: {train_loss:.4f} | train_acc: {train_acc:.4f} | test_loss: {test_loss:.4f} | test_acc: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "g7rCAijahEOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_binary_results = train(model=effnetb2,\n",
        "                                train_dataloader=train_dataloader,\n",
        "                                test_dataloader=test_dataloader,\n",
        "                                optimizer=optimizer,\n",
        "                                loss_fn=loss_fn,\n",
        "                                device=device,\n",
        "                                epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14a2_o9zXadC",
        "outputId": "f3d16b54-c2bc-4022-db68-f3231a0c7108"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model for 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [00:30<04:37, 30.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 0 | train_loss: 0.4001 | train_acc: 0.8466 | test_loss: 0.2441 | test_acc: 0.9697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [00:53<03:26, 25.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 1 | train_loss: 0.1842 | train_acc: 0.9754 | test_loss: 0.1592 | test_acc: 0.9892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:15<02:49, 24.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 2 | train_loss: 0.1305 | train_acc: 0.9824 | test_loss: 0.1220 | test_acc: 0.9905\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [01:36<02:18, 23.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 3 | train_loss: 0.0958 | train_acc: 0.9855 | test_loss: 0.1001 | test_acc: 0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [01:59<01:54, 22.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 4 | train_loss: 0.0817 | train_acc: 0.9877 | test_loss: 0.0842 | test_acc: 0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [02:21<01:30, 22.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 5 | train_loss: 0.0736 | train_acc: 0.9864 | test_loss: 0.0747 | test_acc: 0.9944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [02:43<01:06, 22.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 6 | train_loss: 0.0687 | train_acc: 0.9855 | test_loss: 0.0660 | test_acc: 0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [03:05<00:44, 22.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 7 | train_loss: 0.0619 | train_acc: 0.9868 | test_loss: 0.0612 | test_acc: 0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [03:28<00:22, 22.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 8 | train_loss: 0.0611 | train_acc: 0.9859 | test_loss: 0.0583 | test_acc: 0.9931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [03:49<00:00, 22.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch: 9 | train_loss: 0.0577 | train_acc: 0.9872 | test_loss: 0.0519 | test_acc: 0.9918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save.save_model(model=effnetb2, target_dir=\"models\", model_name=\"effnetb2_binary_food80_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOaz70CCZPnv",
        "outputId": "04e4c4a5-aad6-4d81-8852-9c783edacd52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to: models/effnetb2_binary_food80_model.pth\n"
          ]
        }
      ]
    }
  ]
}