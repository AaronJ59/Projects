{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "78c769ea523b4be68ed2eafcf0494201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0346e4b0c8524e638b0fe247ededafa0",
              "IPY_MODEL_c6a072d2cd0d42268a3dab4fa726d78f",
              "IPY_MODEL_3b8b346192e240cab9484eacb37e7b15"
            ],
            "layout": "IPY_MODEL_a4513f86476d4f30acd79c3dbced01da"
          }
        },
        "0346e4b0c8524e638b0fe247ededafa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed15e23230554067aef56b544e9e13c6",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe9ade773ed4a7d9a73c7298e517a0f",
            "value": "100%"
          }
        },
        "c6a072d2cd0d42268a3dab4fa726d78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad5a9f18384a4c438f79421dbe560b00",
            "max": 988,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d82833bd05bc4420b4bb7105a0130f9c",
            "value": 988
          }
        },
        "3b8b346192e240cab9484eacb37e7b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dbe5249d21940b28c497c62fd7ab2ef",
            "placeholder": "​",
            "style": "IPY_MODEL_93222263b3064a8386ccf4e5f2e355bf",
            "value": " 988/988 [00:29&lt;00:00, 37.05it/s]"
          }
        },
        "a4513f86476d4f30acd79c3dbced01da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed15e23230554067aef56b544e9e13c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe9ade773ed4a7d9a73c7298e517a0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5a9f18384a4c438f79421dbe560b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82833bd05bc4420b4bb7105a0130f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4dbe5249d21940b28c497c62fd7ab2ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93222263b3064a8386ccf4e5f2e355bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import requests\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary\n",
        "\n",
        "\n",
        "try:\n",
        "  from modular import download_image_data, data_setup, train_model, save\n",
        "except:\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\")\n",
        "  !git clone https://github.com/AaronJ59/Projects.git\n",
        "  !mv Projects/BiteID/modular/modular modular\n",
        "  !mv Projects/BiteID/models models\n",
        "  from modular import download_image_data, data_setup, train_model, save\n",
        "  !rm -rf Projects\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w96B62NSAzTD",
        "outputId": "0afb77dc-f5b9-468f-b9c8-b1825b56badb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n",
            "[INFO] Couldn't find going_modular or helper_functions scripts... downloading them from GitHub.\n",
            "Cloning into 'Projects'...\n",
            "remote: Enumerating objects: 159, done.\u001b[K\n",
            "remote: Counting objects: 100% (105/105), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 159 (delta 30), reused 10 (delta 1), pack-reused 54 (from 2)\u001b[K\n",
            "Receiving objects: 100% (159/159), 109.85 MiB | 27.42 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "mv: cannot stat 'Projects/BiteID/models': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "h9pj-xaQ8hFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I must manually import the effnetb2 model state dict and the large dataset zip file"
      ],
      "metadata": {
        "id": "noDuiGw_2AkN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baUfF9M7xLgS",
        "outputId": "19a2d4b9-17ed-4f49-c333-effb072773fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.9.1-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.2 (from gradio)\n",
            "  Downloading gradio_client-1.5.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.8.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.45.1-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.9.1-py3-none-any.whl (57.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.8.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.5.0 gradio-5.9.1 gradio-client-1.5.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.20 ruff-0.8.5 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile"
      ],
      "metadata": {
        "id": "Ziwqq4R2HP6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload multiclass dataset"
      ],
      "metadata": {
        "id": "Qc0BueRdYCPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "directory_name = \"data/large_pizza_hamburger_lasagna_sushi_steak\"\n",
        "\n",
        "try:\n",
        "  os.mkdir(\"data\")\n",
        "  os.mkdir(directory_name)\n",
        "  print(f\"Directory {directory_name} created\")\n",
        "  with zipfile.ZipFile(\"large_pizza_hamburger_lasagna_sushi_steak.zip\", \"r\") as zip_ref:\n",
        "    print(\"Writing zip file to destination\")\n",
        "    zip_ref.extractall(directory_name)\n",
        "except FileExistsError:\n",
        "  print(f\"Directory already exists\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiPtKKoaFyA4",
        "outputId": "f097cc84-3a6e-444e-ea9e-86be4a4e7d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory data/large_pizza_hamburger_lasagna_sushi_steak created\n",
            "Writing zip file to destination\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"data/large_pizza_hamburger_lasagna_sushi_steak/train\"\n",
        "test_dir = \"data/large_pizza_hamburger_lasagna_sushi_steak/test\""
      ],
      "metadata": {
        "id": "CAXRjoGYF0LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def walk_through_dir(dir_path):\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "\n",
        "walk_through_dir(\"data/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etp2gByLKeEY",
        "outputId": "d49914d1-c4fb-4760-afdd-347833a7b17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 directories and 0 images in 'data/'.\n",
            "There are 2 directories and 0 images in 'data/large_pizza_hamburger_lasagna_sushi_steak'.\n",
            "There are 5 directories and 0 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train'.\n",
            "There are 0 directories and 523 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train/hamburger'.\n",
            "There are 0 directories and 526 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train/pizza'.\n",
            "There are 0 directories and 541 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train/steak'.\n",
            "There are 0 directories and 489 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train/sushi'.\n",
            "There are 0 directories and 546 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/train/lasagna'.\n",
            "There are 5 directories and 0 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test'.\n",
            "There are 0 directories and 197 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test/hamburger'.\n",
            "There are 0 directories and 194 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test/pizza'.\n",
            "There are 0 directories and 201 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test/steak'.\n",
            "There are 0 directories and 192 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test/sushi'.\n",
            "There are 0 directories and 204 images in 'data/large_pizza_hamburger_lasagna_sushi_steak/test/lasagna'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upload binary dataset (if testing/experimentation needed)"
      ],
      "metadata": {
        "id": "VedkFBMtYHf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"binary_dataset.zip\", \"r\") as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "metadata": {
        "id": "J4nBl1HyYNlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch"
      ],
      "metadata": {
        "id": "g6k3COeLyBbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(num_classes: int,\n",
        "                          seed:int=42):\n",
        "\n",
        "\n",
        "  # Import efficientnetb2\n",
        "\n",
        "  # Get the weights, transforms of the model and make the model\n",
        "  efficientnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  effnetb2_transform = efficientnetb2_weights.transforms()\n",
        "  effnetb2 = torchvision.models.efficientnet_b2(weights=efficientnetb2_weights)\n",
        "\n",
        "  # Freeze the base layers of efficientnetb2\n",
        "  for param in effnetb2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "  # Change classifier head of effnetb2 to suit 5 classes\n",
        "  torch.manual_seed(seed)\n",
        "  effnetb2.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3, inplace=True),\n",
        "      nn.Linear(in_features=1408, out_features=num_classes),\n",
        "  )\n",
        "\n",
        "  return effnetb2, effnetb2_transform\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "effnetb2, effnetb2_transform = create_effnetb2_model(num_classes=5,\n",
        "                                                           seed=42)\n",
        "\n",
        "# Create effnetb2 model for binary classifier\n",
        "effnetb2_binary, effnetb2_transform = create_effnetb2_model(num_classes=1,\n",
        "                                                            seed=42)"
      ],
      "metadata": {
        "id": "rNvv_aDK8Lh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72d044d3-414e-4bad-9601-ef10f3c3b633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 70.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict for multiclass model\n",
        "\n",
        "effnetb2.load_state_dict(torch.load(f=\"large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth\", map_location=torch.device(\"cpu\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0IoqW618xgj",
        "outputId": "85b9703f-5d7f-4191-c281-14037010f962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-b80b77f5f5d5>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  effnetb2.load_state_dict(torch.load(f=\"large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth\", map_location=torch.device(\"cpu\")))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load state dict for binary model\n",
        "\n",
        "effnetb2_binary.load_state_dict(torch.load(f=\"effnetb2_99_percent_accuracy_binary_classification.pth\", map_location=torch.device(\"cpu\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-CDYlu3e698",
        "outputId": "e92464a1-5b3c-4d35-b4c6-baa3496790da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-c9bcb0b1e3eb>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  effnetb2_binary.load_state_dict(torch.load(f=\"effnetb2_99_percent_accuracy_binary_classification.pth\", map_location=torch.device(\"cpu\")))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = list(Path(test_dir).glob(\"*/*.jpg\"))"
      ],
      "metadata": {
        "id": "KFDb6zhJE_JT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['hamburger', 'lasagna', 'pizza', 'steak', 'sushi']"
      ],
      "metadata": {
        "id": "GAk3taeIIjXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from typing import List, Dict\n",
        "\n",
        "def pred_and_store(image_paths: List[pathlib.Path],\n",
        "                   model: torch.nn.Module,\n",
        "                   transform: torchvision.transforms,\n",
        "                   device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\") -> List[Dict]:\n",
        "\n",
        "  pred_list = []\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  for path in tqdm(image_paths):\n",
        "\n",
        "    pred_dict = {}\n",
        "\n",
        "    class_name = path.parent.stem\n",
        "    pred_dict[\"class\"] = class_name\n",
        "\n",
        "    pred_dict[\"path\"] = path\n",
        "\n",
        "    start_time = timer()\n",
        "\n",
        "    image = Image.open(path)\n",
        "\n",
        "    # Transform the image, add batch dimension and put image on target device\n",
        "    image_transformed = transform(image).unsqueeze(dim=0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      pred_logits = model(image_transformed)\n",
        "\n",
        "      end_time = timer()\n",
        "\n",
        "\n",
        "      pred_probs = torch.softmax(pred_logits, dim=1)\n",
        "      pred_label = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "      pred_dict[\"pred_prob\"] = round(pred_probs.max().cpu().item(), 4)\n",
        "      pred_dict[\"pred_class\"] = class_names[pred_label.cpu()]\n",
        "\n",
        "\n",
        "\n",
        "    pred_dict[\"pred_time\"] = round(end_time - start_time, 4)\n",
        "    pred_dict[\"correct_pred\"] = class_name == class_names[pred_label.cpu()]\n",
        "\n",
        "    # Append created dictionary to the list\n",
        "    pred_list.append(pred_dict)\n",
        "\n",
        "  return pred_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gNmSQdYnITs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_pred_list = pred_and_store(image_paths=image_paths,\n",
        "                                   model=effnetb2,\n",
        "                                   transform=effnetb2_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "78c769ea523b4be68ed2eafcf0494201",
            "0346e4b0c8524e638b0fe247ededafa0",
            "c6a072d2cd0d42268a3dab4fa726d78f",
            "3b8b346192e240cab9484eacb37e7b15",
            "a4513f86476d4f30acd79c3dbced01da",
            "ed15e23230554067aef56b544e9e13c6",
            "ebe9ade773ed4a7d9a73c7298e517a0f",
            "ad5a9f18384a4c438f79421dbe560b00",
            "d82833bd05bc4420b4bb7105a0130f9c",
            "4dbe5249d21940b28c497c62fd7ab2ef",
            "93222263b3064a8386ccf4e5f2e355bf"
          ]
        },
        "id": "9Ptl4Dt-I1gS",
        "outputId": "2afcef90-0e8f-4e79-c793-1f891cbcefd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/988 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78c769ea523b4be68ed2eafcf0494201"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "effnetb2_pred_df = pd.DataFrame(effnetb2_pred_list)\n",
        "\n",
        "effnetb2_pred_df.head()"
      ],
      "metadata": {
        "id": "ID_IxOF3JKTu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "06fad825-fb1a-4803-a54a-82b62041d6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       class                                               path  pred_prob  \\\n",
              "0  hamburger  data/large_pizza_hamburger_lasagna_sushi_steak...     0.9130   \n",
              "1  hamburger  data/large_pizza_hamburger_lasagna_sushi_steak...     0.9996   \n",
              "2  hamburger  data/large_pizza_hamburger_lasagna_sushi_steak...     0.9946   \n",
              "3  hamburger  data/large_pizza_hamburger_lasagna_sushi_steak...     0.9946   \n",
              "4  hamburger  data/large_pizza_hamburger_lasagna_sushi_steak...     0.6806   \n",
              "\n",
              "  pred_class  pred_time  correct_pred  \n",
              "0  hamburger     0.0380          True  \n",
              "1  hamburger     0.0399          True  \n",
              "2  hamburger     0.0349          True  \n",
              "3  hamburger     0.0393          True  \n",
              "4  hamburger     0.0360          True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8de2aa0-adc2-41a5-8fba-021e3c20b275\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>path</th>\n",
              "      <th>pred_prob</th>\n",
              "      <th>pred_class</th>\n",
              "      <th>pred_time</th>\n",
              "      <th>correct_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hamburger</td>\n",
              "      <td>data/large_pizza_hamburger_lasagna_sushi_steak...</td>\n",
              "      <td>0.9130</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>0.0380</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hamburger</td>\n",
              "      <td>data/large_pizza_hamburger_lasagna_sushi_steak...</td>\n",
              "      <td>0.9996</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>0.0399</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hamburger</td>\n",
              "      <td>data/large_pizza_hamburger_lasagna_sushi_steak...</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>0.0349</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hamburger</td>\n",
              "      <td>data/large_pizza_hamburger_lasagna_sushi_steak...</td>\n",
              "      <td>0.9946</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hamburger</td>\n",
              "      <td>data/large_pizza_hamburger_lasagna_sushi_steak...</td>\n",
              "      <td>0.6806</td>\n",
              "      <td>hamburger</td>\n",
              "      <td>0.0360</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8de2aa0-adc2-41a5-8fba-021e3c20b275')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8de2aa0-adc2-41a5-8fba-021e3c20b275 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8de2aa0-adc2-41a5-8fba-021e3c20b275');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9d8111af-a2c5-4460-bd07-100e24318b79\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d8111af-a2c5-4460-bd07-100e24318b79')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9d8111af-a2c5-4460-bd07-100e24318b79 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "effnetb2_pred_df",
              "summary": "{\n  \"name\": \"effnetb2_pred_df\",\n  \"rows\": 988,\n  \"fields\": [\n    {\n      \"column\": \"class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"pizza\",\n          \"lasagna\",\n          \"steak\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 988,\n        \"samples\": [\n          \"data/large_pizza_hamburger_lasagna_sushi_steak/test/pizza/1445608.jpg\",\n          \"data/large_pizza_hamburger_lasagna_sushi_steak/test/pizza/714866.jpg\",\n          \"data/large_pizza_hamburger_lasagna_sushi_steak/test/steak/2600656.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18113515145091644,\n        \"min\": 0.2512,\n        \"max\": 0.9996,\n        \"num_unique_values\": 828,\n        \"samples\": [\n          0.9605,\n          0.9261,\n          0.7636\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"steak\",\n          \"lasagna\",\n          \"sushi\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.006936147487404583,\n        \"min\": 0.0185,\n        \"max\": 0.06,\n        \"num_unique_values\": 249,\n        \"samples\": [\n          0.0324,\n          0.0346,\n          0.0233\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"correct_pred\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "effnetb2_pred_df.correct_pred.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "SblDT7aKNMFO",
        "outputId": "ec90bbbf-a34a-45d2-87ad-db1715af0c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "correct_pred\n",
              "True     893\n",
              "False     95\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>correct_pred</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>True</th>\n",
              "      <td>893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>False</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sucessfully loaded in the state dict"
      ],
      "metadata": {
        "id": "yl34ERD1Yell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement gradio interface"
      ],
      "metadata": {
        "id": "9rMpjkYkcVgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binary_class_names = [\"0_non-food\", \"1_food\"]"
      ],
      "metadata": {
        "id": "ob0ONao7IJfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "effnetb2_binary.to(device)\n",
        "effnetb2.to(device)\n",
        "\n",
        "\n",
        "def image_classification(image):\n",
        "\n",
        "\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  # First, pass image through binary classifier to see if the image is food\n",
        "  image_transformed = effnetb2_transform(image).unsqueeze(dim=0).to(device)\n",
        "\n",
        "  effnetb2_binary.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    pred_logit = effnetb2_binary(image_transformed)\n",
        "\n",
        "    pred_prob = torch.sigmoid(pred_logit)\n",
        "    pred_label = (pred_prob >= 0.5).long()\n",
        "    print(pred_label)\n",
        "    # if the image is food:\n",
        "    if binary_class_names[pred_label] == \"1_food\":\n",
        "\n",
        "      image_transformed = effnetb2_transform(image).unsqueeze(0).to(device) # Adding a batch dimension\n",
        "\n",
        "      effnetb2.eval()\n",
        "\n",
        "      with torch.inference_mode():\n",
        "        pred_logits = effnetb2(image_transformed)\n",
        "\n",
        "        pred_probs = torch.softmax(pred_logits, dim=1)\n",
        "\n",
        "        pred_label = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "        # Dictionary holds the class names and its given probability by the model\n",
        "      pred_dict = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "      end = time.time()\n",
        "      # Time it took to make the prediction\n",
        "      time_to_run = round(end - start, 4)\n",
        "\n",
        "\n",
        "      return pred_dict, time_to_run\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "      return \"Image unrecognizable\", \"Image unrecognizable\"\n",
        "\n"
      ],
      "metadata": {
        "id": "2aUt9S1cYhl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test out the function"
      ],
      "metadata": {
        "id": "y0meETXmTlBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "## Get a random image\n",
        "image_paths = list(Path(test_dir).glob(\"*/*.jpg\"))\n",
        "\n",
        "image_path = random.sample(image_paths, k=1)[0]\n",
        "print(image_path)\n",
        "\n",
        "img = Image.open(image_path)\n",
        "\n",
        "pred_dict, time_to_run = image_classification(img)\n",
        "\n",
        "pred_dict, time_to_run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weeVfn3PToqf",
        "outputId": "9afe918b-e12b-4fd5-ca66-34d0c143abc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data/large_pizza_hamburger_lasagna_sushi_steak/test/hamburger/3305010.jpg\n",
            "tensor([[1]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'hamburger': 0.9968607425689697,\n",
              "  'lasagna': 0.00023155499366112053,\n",
              "  'pizza': 0.000149762854562141,\n",
              "  'steak': 0.0011195661500096321,\n",
              "  'sushi': 0.001638407469727099},\n",
              " 1.5374)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get examples"
      ],
      "metadata": {
        "id": "z7n_G6uUj3oG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = random.sample(image_paths, k=3)\n",
        "examples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6WrPrYgkBsu",
        "outputId": "6b2a6ac6-c0fe-4d9b-adfc-80a9c93b673a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('data/large_pizza_hamburger_lasagna_sushi_steak/test/steak/1956040.jpg'),\n",
              " PosixPath('data/large_pizza_hamburger_lasagna_sushi_steak/test/pizza/849291.jpg'),\n",
              " PosixPath('data/large_pizza_hamburger_lasagna_sushi_steak/test/sushi/72926.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buid the interface"
      ],
      "metadata": {
        "id": "eirHKcb5YnGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(fn=image_classification,\n",
        "                    inputs=gr.Image(type=\"pil\"),\n",
        "                    outputs=[gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
        "                             gr.Label(label=\"Prediction Time (s)\")],\n",
        "                    examples=examples,\n",
        "                    title=\"BiteID\",\n",
        "                    description=\"Upload an image, and the computer vision model will predict whether it’s pizza, hamburger, lasagna, sushi, or steak. Try it out and see which dish it classifies!\")\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch(debug=False, # print errors locally?\n",
        "            share=True) # generate a publically shareable URL?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "clSY6CJ_YrBF",
        "outputId": "ece7d7b8-ec32-453d-b17f-eeb4fc1b2af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://820cb5790fb3711df0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://820cb5790fb3711df0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Gradio app structure"
      ],
      "metadata": {
        "id": "sfWQuDFJLCJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating demos folder"
      ],
      "metadata": {
        "id": "MnxOFT9GLIQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "biteid_demo_path = Path(\"demos/biteid/\")\n",
        "\n",
        "if biteid_demo_path.exists():\n",
        "  shutil.rmtree(biteid_demo_path)\n",
        "\n",
        "biteid_demo_path.mkdir(parents=True,\n",
        "                       exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "ameaLxUGLT8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating example images folder"
      ],
      "metadata": {
        "id": "7gwr1tHbNbnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "demo_examples_path = biteidv2_demo_path / \"examples\"\n",
        "demo_examples_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for example in examples:\n",
        "  shutil.copy(example, demo_examples_path)\n"
      ],
      "metadata": {
        "id": "20P1Es-FNjow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving models to demo folder"
      ],
      "metadata": {
        "id": "NJDeG5-cTBjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "  shutil.move(\"effnetb2_99_percent_accuracy_binary_classification.pth\", \"demos/biteid\")\n",
        "  shutil.move(\"large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth\", \"demos/biteid\")\n",
        "except:\n",
        "  print(f\"Models have already been moved or they haven't been uploaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7CWeBY9RTEbY",
        "outputId": "c028bfc7-213a-42d6-8331-b0c1dc3ae58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'demos/biteid/large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model.py"
      ],
      "metadata": {
        "id": "vLrr1HggVGdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/biteid/model.py\n",
        "\n",
        "def create_effnetb2_model(num_classes: int,\n",
        "                          seed:int=42):\n",
        "\n",
        "\n",
        "  # Get the weights, transforms of the model and make the model\n",
        "  efficientnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  effnetb2_transform = efficientnetb2_weights.transforms()\n",
        "  effnetb2 = torchvision.models.efficientnet_b2(weights=efficientnetb2_weights)\n",
        "\n",
        "  # Freeze the base layers of efficientnetb2\n",
        "  for param in effnetb2.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "\n",
        "  # Change classifier head of effnetb2 to suit 5 classes\n",
        "  torch.manual_seed(seed)\n",
        "  effnetb2.classifier = nn.Sequential(\n",
        "      nn.Dropout(p=0.3, inplace=True),\n",
        "      nn.Linear(in_features=1408, out_features=num_classes),\n",
        "  )\n",
        "\n",
        "  return effnetb2, effnetb2_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F79HqCCuVJBe",
        "outputId": "ee14c4a5-2829-4cb1-9c2d-1e4c60f5881b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/biteid/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating app.py"
      ],
      "metadata": {
        "id": "anov_s42X-A1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/biteid/app.py\n",
        "\n",
        "from model import create_effnetb2_model\n",
        "\n",
        "import time\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "class_names = [\"hamburger\", \"lasagna\", \"pizza\", \"steak\", \"sushi\"]\n",
        "\n",
        "binary_class_names = [\"0_non-food\", \"1_food\"]\n",
        "\n",
        "effnetb2, effnetb2_transform = create_effnetb2_model(num_classes=5)\n",
        "\n",
        "effnetb2_binary, effnetb2_transform = create_effnetb2_model(num_classes=1)\n",
        "\n",
        "\n",
        "# Load state dicts\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(f=\"large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth\",\n",
        "               map_location=torch.device(\"cpu\")\n",
        "               )\n",
        "    )\n",
        "\n",
        "\n",
        "effnetb2_binary.load_state_dict(\n",
        "    torch.load(\n",
        "        f=\"effnetb2_99_percent_accuracy_binary_classification.pth\",\n",
        "        map_location=torch.device(\"cpu\")\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "def image_classification(image):\n",
        "\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  # First, pass image through binary classifier to see if the image is food\n",
        "  image_transformed = effnetb2_transform(image).unsqueeze(dim=0).to(device)\n",
        "\n",
        "  effnetb2_binary.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    pred_logit = effnetb2_binary(image_transformed)\n",
        "\n",
        "    pred_prob = torch.sigmoid(pred_logit)\n",
        "    pred_label = (pred_prob >= 0.5).long()\n",
        "    print(pred_label)\n",
        "    # if the image is food:\n",
        "    if binary_class_names[pred_label] == \"1_food\":\n",
        "\n",
        "      image_transformed = effnetb2_transform(image).unsqueeze(0).to(device) # Adding a batch dimension\n",
        "\n",
        "      effnetb2.eval()\n",
        "\n",
        "      with torch.inference_mode():\n",
        "        pred_logits = effnetb2(image_transformed)\n",
        "\n",
        "        pred_probs = torch.softmax(pred_logits, dim=1)\n",
        "\n",
        "        pred_label = torch.argmax(pred_probs, dim=1)\n",
        "\n",
        "        # Dictionary holds the class names and its given probability by the model\n",
        "      pred_dict = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "      end = time.time()\n",
        "      # Time it took to make the prediction\n",
        "      time_to_run = round(end - start, 4)\n",
        "\n",
        "\n",
        "      return pred_dict, time_to_run\n",
        "\n",
        "    else:\n",
        "      return \"Image unrecognizable\", \"Image unrecognizable\"\n",
        "\n",
        "\n",
        "examples = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "\n",
        "demo = gr.Interface(fn=image_classification,\n",
        "                    inputs=gr.Image(type=\"pil\"),\n",
        "                    outputs=[gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
        "                             gr.Label(label=\"Prediction Time (s)\")],\n",
        "                    examples=examples,\n",
        "                    title=\"BiteID🍔\",\n",
        "                    description=\"Upload an image, and the computer vision model will predict whether it’s pizza, hamburger, lasagna, sushi, or steak. Try it out and see which dish it classifies!\")\n",
        "\n",
        "# Launch the demo!\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKyQy7qUX_gM",
        "outputId": "eb425d20-46be-49b2-df62-6febfbe90345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demos/biteid/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating requirements.txt"
      ],
      "metadata": {
        "id": "3xfTjBOohTP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/biteid/requirements.txt\n",
        "torch==2.5.1\n",
        "gradio==5.9.1\n",
        "torchvision==0.20.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASCKu3GWhUzz",
        "outputId": "59ac867c-718c-486b-9e03-8508c55cb0d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing demos/biteid/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "iuWPYgMfxGOr",
        "outputId": "ada4425b-b043-412b-8d9b-e9b9f26ce563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls demos/biteid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhr3hENukzlU",
        "outputId": "bbfbee4f-7187-409b-bb00-8ecc2344f5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py\n",
            "effnetb2_99_percent_accuracy_binary_classification.pth\n",
            "examples\n",
            "large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth\n",
            "model.py\n",
            "requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading app files"
      ],
      "metadata": {
        "id": "hkNSFzaok_US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change into and zip the biteid folder. Everything after -x is excluded from being zipped\n",
        "!cd demos/biteid && zip -r ../biteid.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"demos/biteid.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "eVfve9jMlCN4",
        "outputId": "bc7af7c3-0e06-4e79-ea66-358513043e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app.py (deflated 60%)\n",
            "  adding: effnetb2_99_percent_accuracy_binary_classification.pth (deflated 8%)\n",
            "  adding: examples/ (stored 0%)\n",
            "  adding: examples/849291.jpg (deflated 1%)\n",
            "  adding: examples/72926.jpg (deflated 0%)\n",
            "  adding: examples/1956040.jpg (deflated 16%)\n",
            "  adding: large_dataset_effnetb2_90_percent_accuracy_10_epochs.pth (deflated 8%)\n",
            "  adding: model.py (deflated 51%)\n",
            "  adding: requirements.txt (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8cee7dcd-88b3-480a-84cd-66d6bedf20d7\", \"biteid.zip\", 57769111)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}